#!/usr/bin/python
# -*- coding:utf-8 -*-
import torch
from torch import nn
import warnings



class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.max_pool = nn.AdaptiveMaxPool1d(1)

        self.fc1 = nn.Conv1d(in_planes, in_planes // ratio, 1, bias=False)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Conv1d(in_planes // ratio, in_planes, 1, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))
        out = avg_out + max_out
        return self.sigmoid(out)


class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        padding = 3 if kernel_size == 7 else 1

        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding,
                               bias=False)  # 7,3     3,1
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        x = self.conv1(x)
        return self.sigmoid(x)


class CBAM(nn.Module):
    def __init__(self, in_planes, ratio=16, kernel_size=7):
        super(CBAM, self).__init__()
        self.ca = ChannelAttention(in_planes, ratio)
        self.sa = SpatialAttention(kernel_size)

    def forward(self, x):
        out = x * self.ca(x)
        result = out * self.sa(out)
        return result



class AconC(nn.Module):
    r""" ACON activation (activate or not).
    # AconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is a learnable parameter
    # according to "Activate or Not: Learning Customized Activation" <https://arxiv.org/pdf/2009.04759.pdf>.
    """

    def __init__(self, width):
        super().__init__()
        self.p1 = nn.Parameter(torch.randn(1, width, 1))
        self.p2 = nn.Parameter(torch.randn(1, width, 1))
        self.beta = nn.Parameter(torch.ones(1, width, 1))
    def forward(self, x):
        return (self.p1 * x - self.p2 * x) * torch.sigmoid(self.beta * (self.p1 * x - self.p2 * x)) + self.p2 * x


class MetaAconC(nn.Module):
    r""" ACON activation (activate or not).
    # MetaAconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is generated by a small network
    # according to "Activate or Not: Learning Customized Activation" <https://arxiv.org/pdf/2009.04759.pdf>.
    """

    def __init__(self, width, r=16):
        super().__init__()
        self.fc1 = nn.Conv1d(width, max(r, width // r), kernel_size=1, stride=1, bias=True)
        self.bn1 = nn.BatchNorm1d(max(r, width // r), track_running_stats=True)
        self.fc2 = nn.Conv1d(max(r, width // r), width, kernel_size=1, stride=1, bias=True)
        self.bn2 = nn.BatchNorm1d(width, track_running_stats=True)
        self.p1 = nn.Parameter(torch.randn(1, width, 1))
        self.p2 = nn.Parameter(torch.randn(1, width, 1))

    def forward(self, x):
        beta = torch.sigmoid(self.bn2(self.fc2(self.bn1(self.fc1(x.mean(dim=2, keepdims=True))))))
        return (self.p1 * x - self.p2 * x) * torch.sigmoid(beta * (self.p1 * x - self.p2 * x)) + self.p2 * x


class CoordAtt(nn.Module):
    def __init__(self, inp, oup, reduction=32):
        super(CoordAtt, self).__init__()
        # self.pool_w = nn.AdaptiveAvgPool1d(1)
        self.pool_w = nn.AdaptiveMaxPool1d(1)
        mip = max(6, inp // reduction)
        self.conv1 = nn.Conv1d(inp, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm1d(mip, track_running_stats=False)
        self.act = MetaAconC(mip)
        self.conv_w = nn.Conv1d(mip, oup, kernel_size=1, stride=1, padding=0)

    def forward(self, x):
        identity = x
        # print(identity.size())
        # torch.Size([64, 16, 1010])
        n, c, w = x.size()
        x_w = self.pool_w(x)
        # print(x_w.size())
        # torch.Size([64, 16, 1])
        y = torch.cat([identity, x_w], dim=2)
        # print(y.size())
        # torch.Size([64, 16, 1011])
        y = self.conv1(y)
        # print(y.size())
        # torch.Size([64, 6, 1011])
        y = self.bn1(y)
        # print(y.size())
        # torch.Size([64, 6, 1011])
        y = self.act(y)
        # print(y.detach().numpy().shape)
        # (64, 6, 1011)
        x_ww, x_c = torch.split(y, [w, 1], dim=2)
        # print(x_ww.detach().numpy().shape)
        # (64, 6, 1010)
        # print(x_c.detach().numpy().shape)
        # (64, 6, 1)
        a_w = self.conv_w(x_ww)
        # print(a_w.size())
        # torch.Size([64, 16, 1010])
        a_w = a_w.sigmoid()
        # print(a_w.size())
        out = identity * a_w
        # print(out.size())
        # torch.Size([64, 16, 1010])
        return out


class CNN(nn.Module):
    def __init__(self, pretrained=False, in_channel=1, out_channel=10):
        super(CNN, self).__init__()
        if pretrained == True:
            warnings.warn("Pretrained model is not available")

        self.layer1 = nn.Sequential(

            nn.Conv1d(in_channel, 16, kernel_size=15),

            nn.BatchNorm1d(16),

            nn.ReLU(inplace=True),
        )

        self.layer11 = CoordAtt(16, 16)

        self.layer2 = nn.Sequential(
            nn.Conv1d(16, 32, kernel_size=3),
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),

            nn.MaxPool1d(kernel_size=2, stride=2),
            )

        self.layer22 = CoordAtt(32, 32)

        self.layer3 = nn.Sequential(
            nn.Conv1d(32, 64, kernel_size=3),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True)
        )

        self.layer33 = CoordAtt(64, 64)

        self.layer4 = nn.Sequential(
            nn.Conv1d(64, 128, kernel_size=3),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.AdaptiveMaxPool1d(4)

            # nn.MaxPool1d(2, 2)
            )

        self.layer6 = CoordAtt(128, 128)
        # (64,128,256)

        self.layer7 = nn.Sequential(
            nn.LSTM(256, 130, bidirectional=True)
        )

        self.layer8 = nn.Sequential(nn.AdaptiveAvgPool1d(4))

        self.layer5 = nn.Sequential(
            nn.Linear(128 * 4, 256),
            nn.ReLU(inplace=True),

            nn.Dropout())

        self.layer44 = CoordAtt(128, 64)

        self.layer55 = ChannelAttention(256)

        self.p1_1 = nn.Sequential(nn.Conv1d(1, 64, kernel_size=18, stride=2),
                                  nn.BatchNorm1d(64, track_running_stats=False),
                                  MetaAconC(64))
        self.p1_2 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=10, stride=2),
                                  nn.BatchNorm1d(128, track_running_stats=False),
                                  MetaAconC(128))
        self.p1_3 = nn.MaxPool1d(2, 2)
        self.p2_1 = nn.Sequential(nn.Conv1d(1, 16, kernel_size=6, stride=1),
                                  nn.BatchNorm1d(16, track_running_stats=False),
                                  MetaAconC(16))
        self.p2_2 = nn.Sequential(nn.Conv1d(16, 32, kernel_size=6, stride=1),
                                  nn.BatchNorm1d(32, track_running_stats=False),
                                  MetaAconC(32))
        self.p2_3 = nn.MaxPool1d(2, 2)
        self.p2_4 = nn.Sequential(nn.Conv1d(32, 64, kernel_size=6, stride=1),
                                  nn.BatchNorm1d(64, track_running_stats=False),
                                  MetaAconC(64))
        self.p2_5 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=6, stride=2),
                                  nn.BatchNorm1d(128, track_running_stats=False),
                                  MetaAconC(128))
        self.p2_6 = nn.MaxPool1d(2, 2)
        self.p3_0 = CoordAtt(128, 128)
        self.p3_1 = nn.Sequential(nn.LSTM(124, 64, bidirectional=True))  #
        # self.p3_2 = nn.Sequential(nn.LSTM(128, 512))
        self.p3_3 = nn.Sequential(nn.AdaptiveAvgPool1d(4))

        self.p4 = nn.Sequential(
            nn.Linear(128 * 4, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.6)
        )

    def forward(self, x):
        p1 = self.p1_3(self.p1_2(self.p1_1(x)))
        p2 = self.p2_6(self.p2_5(self.p2_4(self.p2_3(self.p2_2(self.p2_1(x))))))
        encode = torch.mul(p1, p2)
        # p3 = self.p3_2(self.p3_1(encode))
        # (128,30,124)
        # print(encode.detach().numpy().shape)
        p3_0 = self.p3_0(encode).permute(1, 0, 2)
        # print(p3_0.detach().numpy().shape)
        # (30, 128, 124)
        p3_2, _ = self.p3_1(p3_0)
        # print(p3_2.detach().numpy().shape)
        # (30, 128, 128)
        # p3_2, _ = self.p3_2(p3_1)
        p3_11 = p3_2.permute(1, 0, 2)  #
        # print(p3_11.detach().numpy().shape)
        # (128, 30, 128)
        p3_12 = self.p3_3(p3_11)
        # (64,30,16)

        # print(p3_12.detach().numpy().shape)
        # (128, 30)
        # p3_11 = h1.permute(1,0,2)
        # p3 = self.p3(encode)
        # p3 = p3.squeeze()
        # p4 = self.p4(p3_11)  # LSTM(seq_len, batch, input_size)
        # p4 = self.p4(encode)
        # x = self.p4(p3_12)
        # print(x.size())
        x = p3_12.view(p3_12.size(0), -1)
        x = self.p4(x)
        return x

